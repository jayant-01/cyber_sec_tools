import requests
import re
from typing import Dict, List, Optional
import logging
from datetime import datetime
import json
import time
from bs4 import BeautifulSoup
import urllib.parse

class GitHubDorker:
    def __init__(self, target: str):
        self.target = target
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        # Common GitHub dorks for public repositories
        self.dorks = {
            "Repositories": [
                f'org:{target}',
                f'user:{target}',
                f'"{target}" in:name',
                f'"{target}" in:description'
            ],
            "Code": [
                f'"{target}" in:path',
                f'"{target}" in:file',
                f'filename:README.md "{target}"',
                f'filename:CONTRIBUTING.md "{target}"'
            ],
            "Issues": [
                f'"{target}" in:title is:issue',
                f'"{target}" in:body is:issue'
            ],
            "Discussions": [
                f'"{target}" in:title is:discussion',
                f'"{target}" in:body is:discussion'
            ],
            "Documentation": [
                f'filename:docs "{target}"',
                f'filename:documentation "{target}"',
                f'filename:*.md "{target}"'
            ],
            "Configuration": [
                f'filename:config "{target}"',
                f'filename:*.conf "{target}"',
                f'filename:*.config "{target}"'
            ],
            "API": [
                f'filename:api "{target}"',
                f'filename:swagger "{target}"',
                f'filename:openapi "{target}"'
            ],
            "Security": [
                f'filename:security "{target}"',
                f'filename:vulnerability "{target}"',
                f'filename:advisory "{target}"'
            ]
        }

    def search_github(self, query: str) -> List[Dict]:
        """Search GitHub using web scraping"""
        results = []
        page = 1
        
        while True:
            try:
                # Construct the search URL
                encoded_query = urllib.parse.quote(query)
                url = f"https://github.com/search?q={encoded_query}&type=code&p={page}"
                
                response = self.session.get(url)
                if response.status_code != 200:
                    logging.error(f"Error accessing GitHub: {response.status_code}")
                    break
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Find all code search results
                code_results = soup.find_all('div', {'class': 'code-list-item'})
                if not code_results:
                    break
                
                for result in code_results:
                    try:
                        # Extract repository information
                        repo_link = result.find('a', {'class': 'Link--secondary'})
                        file_link = result.find('a', {'class': 'Link--primary'})
                        
                        if repo_link and file_link:
                            repo_name = repo_link.text.strip()
                            file_path = file_link.text.strip()
                            repo_url = f"https://github.com{repo_link['href']}"
                            file_url = f"https://github.com{file_link['href']}"
                            
                            # Get repository description if available
                            description = ""
                            desc_elem = result.find('p', {'class': 'mb-1'})
                            if desc_elem:
                                description = desc_elem.text.strip()
                            
                            results.append({
                                'repository': {
                                    'full_name': repo_name,
                                    'description': description,
                                    'html_url': repo_url
                                },
                                'path': file_path,
                                'html_url': file_url
                            })
                    except Exception as e:
                        logging.error(f"Error parsing result: {e}")
                        continue
                
                # Check if there's a next page
                next_button = soup.find('a', {'class': 'next_page'})
                if not next_button or 'disabled' in next_button.get('class', []):
                    break
                
                page += 1
                time.sleep(2)  # Respect GitHub's rate limits
                
            except Exception as e:
                logging.error(f"Error searching GitHub: {e}")
                break
        
        return results

    def analyze_results(self, results: List[Dict]) -> Dict[str, List[Dict]]:
        """Analyze and categorize the search results"""
        categorized = {
            "repositories": [],
            "issues": [],
            "discussions": [],
            "documentation": [],
            "configuration": [],
            "api_docs": [],
            "security": []
        }
        
        for result in results:
            try:
                path = result['path'].lower()
                
                # Categorize based on file path
                if any(key in path for key in ['readme', 'contributing', 'docs', 'documentation']):
                    categorized['documentation'].append(result)
                elif any(key in path for key in ['config', 'conf', 'settings']):
                    categorized['configuration'].append(result)
                elif any(key in path for key in ['api', 'swagger', 'openapi']):
                    categorized['api_docs'].append(result)
                elif any(key in path for key in ['security', 'vulnerability', 'advisory']):
                    categorized['security'].append(result)
                elif 'issue' in path or 'pull' in path:
                    categorized['issues'].append(result)
                elif 'discussion' in path:
                    categorized['discussions'].append(result)
                else:
                    categorized['repositories'].append(result)
                
            except Exception as e:
                logging.error(f"Error analyzing result: {e}")
                continue
        
        return categorized

    def run_dorks(self) -> Dict:
        """Run all GitHub dorks and return results"""
        all_results = {}
        
        for category, dorks in self.dorks.items():
            category_results = []
            for dork in dorks:
                try:
                    results = self.search_github(dork)
                    if results:
                        analyzed = self.analyze_results(results)
                        category_results.append({
                            "dork": dork,
                            "results": analyzed
                        })
                except Exception as e:
                    logging.error(f"Error running dork {dork}: {e}")
                    continue
                
                time.sleep(2)  # Respect GitHub's rate limits
            
            if category_results:
                all_results[category] = category_results
        
        return all_results

    def generate_report(self, results: Dict) -> str:
        """Generate a human-readable report of the GitHub dorking results"""
        if not results:
            return "No GitHub dorking results found."
        
        report = f"GitHub Dorking Report for {self.target}\n"
        report += "=" * 50 + "\n\n"
        
        for category, dork_results in results.items():
            report += f"{category}:\n"
            report += "-" * 20 + "\n"
            
            for dork_result in dork_results:
                report += f"\nDork: {dork_result['dork']}\n"
                
                for result_type, items in dork_result['results'].items():
                    if items:
                        report += f"\n  {result_type.upper()}:\n"
                        for item in items:
                            report += f"    - Repository: {item['repository']['full_name']}\n"
                            report += f"      File: {item['path']}\n"
                            report += f"      URL: {item['html_url']}\n"
                            if item['repository']['description']:
                                report += f"      Description: {item['repository']['description']}\n"
                
                report += "\n"
        
        return report 